{
  "tool_name": "autoperfpy",
  "tool_version": "1.0",
  "timestamp": "2026-02-22T02:22:55.013502+00:00",
  "platform": {
    "hardware_name": "unknown",
    "os": "Windows 11",
    "framework": "pytorch",
    "framework_version": "2.5.1+cu121"
  },
  "workload": {
    "name": "html_report_data",
    "workload_type": "inference",
    "batch_size": 1,
    "steps": 0
  },
  "metrics": {
    "throughput_samples_per_sec": 0.0,
    "latency_p50_ms": 0.0,
    "latency_p95_ms": 0.0,
    "latency_p99_ms": 0.0,
    "memory_utilization_percent": 0.0,
    "communication_overhead_percent": null,
    "power_consumption_watts": null,
    "energy_per_step_joules": null,
    "performance_per_watt": null,
    "temperature_celsius": null,
    "scaling_efficiency_pct": null,
    "ttft_ms": null,
    "tokens_per_sec": 22.04010336122793,
    "decode_tpt_ms": null
  },
  "regression": {
    "baseline_id": null,
    "delta_percent": 0.0,
    "status": "pass",
    "failed_metrics": []
  },
  "kv_cache": null,
  "tool_payload": {
    "backend": "mock",
    "model": "mock-model",
    "num_prompts": 32,
    "mean_ttft_ms": 124.76764154654872,
    "p99_ttft_ms": 162.96046890849584,
    "mean_tpot_ms": 45.37183803589415,
    "p99_tpot_ms": 69.64604827822379,
    "throughput_tokens_per_sec": 22.04010336122793
  },
  "schema_version": "1.1.0"
}